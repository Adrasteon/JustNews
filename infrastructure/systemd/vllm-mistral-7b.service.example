[Unit]
Description=JustNews vLLM Mistral-7B Service (example)
After=network.target

[Service]
Type=simple
# Expects vllm to be available in PATH (ideally in conda env)
ExecStart=/usr/bin/env bash -lc 'export VLLM_MODEL="mistralai/Mistral-7B-Instruct-v0.3"; export PYTORCH_CUDA_ALLOC_CONF="expandable_segments:True"; exec vllm --model $VLLM_MODEL --dtype bf16 --max-batch-size 4 --port 7060'
Restart=on-failure
RestartSec=10
MemoryMax=48G
CPUQuota=80%
LimitNOFILE=65536
Environment=PATH=/home/adra/miniconda3/envs/justnews-py312/bin:/usr/bin:/bin

[Install]
WantedBy=multi-user.target
