name: justnews-py312
channels:
  - pytorch
  - nvidia
  - conda-forge
  - defaults
dependencies:
  - python=3.12.11
  - pip
  - mamba

  # Core build tooling
  - gcc_linux-64
  - gxx_linux-64

  # Core scientific stack
  - numpy=2.2.4
  - scipy>=1.11
  - pandas>=2.0
  - scikit-learn>=1.3
  - networkx>=3.0
  - numba=0.61.2  # required by vLLM runtime for some decode helpers (note: compatible with numpy<=2.2)

  # Database connectivity (use MariaDB connector by default)
  - mysql-connector-python>=9.0
  - sqlalchemy>=2.0

  # NLP and ML
  - spacy>=3.7
  - sentence-transformers=3.0.1
  - transformers=4.56.0
  - tokenizers=0.22.0
  - accelerate=1.10.1
  - bitsandbytes=0.47.0
  - safetensors=0.4.3
  - sentencepiece
  - tiktoken>=0.12
  - onnxruntime>=1.18

  # PyTorch GPU stack (see docs/operations/VLLM_MISTRAL_7B_SETUP.md for CUDA/pip wheel install notes)
  - pytorch=2.9.0
  - torchvision=0.24.0
  - torchaudio=2.9.0
  - nvidia-ml-py=13.580.82
  - numba=0.61.2  # ensure NumPy <= 2.2 when combined with this version

  # Web/API stack
  - fastapi>=0.120
  - uvicorn=0.29.*
  - uvicorn-standard=0.29.*
  - starlette>=0.49
  - requests>=2.31
  - httpx>=0.28
  - aiohttp>=3.9
  - aiofiles>=23.2
  - aiosqlite>=0.19
  - python-dotenv>=1.0
  - orjson>=3.9
  - playwright=1.55.*
  - tf-playwright-stealth=1.2.0
  - openai=2.6.1
  - django=5.2.8
  # These packages are installed via pip instead of conda to avoid channel
  # resolution conflicts (they are not published as first-class conda packages
  # on the configured channels at the moment).

  # Observability and utilities
  - prometheus_client>=0.19
  - opentelemetry-api>=1.20
  - opentelemetry-sdk>=1.20
  - opentelemetry-instrumentation>=0.41b0
  - opentelemetry-instrumentation-fastapi>=0.41b0
  - opentelemetry-instrumentation-requests>=0.41b0
  - protobuf=5.29.3
  - thrift>=0.22
  - wrapt>=1.14
  - psutil>=5.9
  - tqdm
  - uvloop=0.21.*
  - httptools
  - watchfiles
  - pyyaml
  - ujson
  - requests-oauthlib

  # Content extraction / parsing
  - trafilatura>=1.6
  - readability-lxml>=0.8
  - justext>=3.0
  - extruct>=0.17
  - w3lib>=2.1
  - langdetect>=1.0
  - lxml>=4.9
  - dateparser
  - beautifulsoup4
  - html5lib
  - cssselect
  - tld
  - lxml-html-clean

  # Testing and quality tooling
  - pytest>=7.4
  - pytest-asyncio>=0.21
  - pytest-cov>=4.1
  - coverage
  - mypy>=1.7
  - ruff>=0.1.6

  - pip:
    - chromadb>=1.3.3
    - crawl4ai>=0.7.4
    - litellm>=1.79.0
    - googleapis-common-protos>=1.59.1
    - websockets==14.0.0
    - patchright==1.55.2
    - opentelemetry-exporter-otlp==1.21.0
    - opentelemetry-exporter-jaeger==1.21.0
    # Recommended runtime packages (install exact torch wheel for CUDA 12.8 via PyTorch wheel index):
    # pip install --upgrade --force-reinstall "torch==2.9.0+cu128" -f https://download.pytorch.org/whl/torch_stable.html
    # Build bitsandbytes from source to ensure CUDA binary matches your toolchain:
    # pip install --no-binary :all: bitsandbytes==0.47.0
    - vllm==0.12.0
    - flashinfer==0.5.3
    - torch-c-dlpack-ext
    - torchmetrics
    - accelerate
    - safetensors

